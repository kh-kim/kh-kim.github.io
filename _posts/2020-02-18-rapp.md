---
title: RaPP - Novelty Detection with Reconstruction along Projection Pathway
key: 20200218
tags: AnomalyDetection
category: blog
---

# RaPP - Novelty Detection with Reconstruction along Projection Pathway

이번 포스팅은 마키나락스에서 2020년 4월에 에티오피아에서 열리는 ICLR에 출판한 페이퍼인 RaPP [1] 방법에 대해서 다루도록 하겠습니다.
이 방법은 기존의 오토인코더(autoencoders, AE)에서의 reconstruction error 기반의 이상탐지(anomaly detection)를 확장한 것으로, 학습을 위한 training objective는 수정하지 않고 테스트 과정에서의 anomaly score metric만을 수정하여 이상탐지 성능을 끌어올린 것에 의의가 있습니다.
이 포스팅을 통해서 RaPP의 motivation과 직관적인 해석, 그리고 수식적인 해석과 실험 결과를 전달하고자 합니다.
추가로 페이퍼에 미처 적지 못했던 RaPP의 인사이트를 공유하고자 합니다.

### Overall Process

좀 더 나아가기에 앞서, RaPP의 동작 방식에 대해서 설명하고자 합니다.
앞서 언급하였듯이 RaPP는 기존의 다양한 오토인코더 위에서 동작하는 anomaly score metric 입니다.
따라서 오토인코더의 training objective의 수정 없이, 단순히 이미 학습된 오토인코더를 활용하여 더 나은 이상탐지 성능을 제공합니다.

RaPP의 동작 원리는 다음과 같습니다.

![RaPP 수행 방법](/assets/images/20200218/1.png)

먼저, 입력 샘플 $x$ 를 오토인코더 $A$ 의 인코더 $g$ 와 디코더 $f$ 에 차례로 통과시킵니다.
그럼 우리는 결과물 $\hat{x}$ 을 얻을 수 있습니다.
이때 기존의 reconstruction error 기반의 anomaly score는 다음과 같이 정의 될 수 있습니다.

$$
\begin{aligned}
\text{score}(x)&=||f\circ{g}(x)-x||_2 \\
&=||\hat{x}-x||_2
\end{aligned}
$$

이때 인코더 내부의 $i$ 번째 레이어 $g_i$ 의 결과값을 $h_i$ 라고 하겠습니다.

$$
h_i=g_{1:i}(x)
$$

RaPP는 여기서 $\hat{x}$ 을 다시 인코더에 통과시킵니다.
이때 마찬가지로 인코더 내부의 각 레이어의 결과값을 구할 수 있을 것입니다.
$i$ 번째 레이어의 그것을 $\hat{h}_i$ 라고 하겠습니다.

$$
\begin{aligned}
\hat{h}_i&=g_{1:i}(\hat{x}) \\
&=g_{1:i}\circ{f}\circ{g}(x)
\end{aligned}
$$

그럼 RaPP는 다음과 같이 $h_i$ 과 $\hat{h}_i$ 들의 concatenation 한 결과 벡터 사이의 distance로 정의됩니다.

$$
\text{RaPP}(x)=\Big|\Big|[h_1;\cdots;h_\ell]-[\hat{h}_1;\cdots;\hat{h}_\ell]\Big|\Big|
$$

여기서 경우에 따라 L2 Norm 또는 mahalanobis distance를 distance metric으로 사용합니다.

## Motivation

RaPP는 굉장히 단순한 방법으로 anomaly score metric의 성능을 향상 시킵니다.
기존 복원 오차(reconstruction error) 기반의 이상탐지 기법은 보통 잘 동작하지만 가끔 아래와 같은 상황을 맞이할 수 있습니다.

아래의 예제는 MNIST에서 실제 오토인코더를 활용하여 reconstruction error 기반의 이상탐지를 수행할 경우 겪게 되는 현상입니다.
'1'을 novelty class로 설정하고, 나머지 9개의 숫자들을 학습데이터로 삼아 학습하였을 때, 테스트 과정에서 오토인코더는 학습 과정에서 보지 못했던 '1' 클래스의 샘플들을 성공적으로 복원해냅니다.
심지어 아래의 그림에 따르면 학습에서 보았던 클래스에 속하는 일부 샘플들보다도 복원 오차가 더 낮은 것을 볼 수 있습니다.

![MNIST에서 '1'이 novelty class인 경우의 성능 저하 현상](/assets/images/20200218/2.png)

이러한 경우에는 reconstruction error를 기준으로 anomalous sample을 탐지하는 전략이 실패합니다.
왼쪽 그림은 reconstruction error 기반의 novelty detection 결과이고, 0.37이라는 매우 낮은 AUROC 값을 보여줍니다.
심지어 0.5보다 낮은 것은 오히려 reconstruction error가 낮은 것을 선택하는 것이 더 나은 전략임을 말합니다.
아마도 우리는 '1'은 모양이 너무 단순하여, 다른 9개의 클래스로부터 학습된 특징(feature)들로 표현이 가능하기 때문에 복원이 잘 된 것이 아닐까 추측해볼 수 있습니다.

하지만 오른쪽의 RaPP의 NAP를 사용한 경우에는 성공적으로 novelty detection을 수행하는 것을 볼 수 있습니다.
이처럼 단순히 오토인코더의 입력과 출력을 비교하는 전략은 훌륭하지만 아쉬움이 여전이 남아있습니다.
RaPP는 이때의 아쉬움을 달래고자, 양 끝의 데이터만 비교하는 방법을 좀 더 개선하고자 합니다.

만약 오토인코더의 입력과 출력만 비교하는 대신에, 인코더의 각 hidden layer의 출력값들과 디코더의 hidden layer의 출력값들을 비교하는 것은 어떨까요?
지난 포스팅에서 우리는 오토인코더의 인코더는 압축을 담당하고, 디코더는 압축의 복원(해제)을 담당한다고 이야기하였습니다.
그럼 압축 중간 과정 결과물과 복원 중간 과정의 결과물을 비교한다면, 기존의 입력/출력 값만을 비교하는 것에 비해서 훨씬 더 자세한 비교를 수행할 수 있지 않을까요?

![인코더와 디코더의 대응되는 중간 레이어 결과값을 비교한다면?](/assets/images/20200218/3.png)

하지만 아쉽게도 이 방법은 기존의 방법에서는 쉽지 않습니다.
우선 오토인코더는 입력과 출력의 차이만을 최소화하도록 학습되었기 때문입니다. — 그리고 그전에 오토인코더가 당연히 대칭의 구조를 가지고 있어야겠지요.

$$
\mathcal{L}(\theta)=\sum_{i=1}^{N}{||x_i-A_\theta(x_i)||}
$$

따라서 딥러닝의 학습 과정에서 신경망은 입력 $x_i$ 와 출력 $A(x_i)$ 에 대해서만 신경쓸 뿐, 인코더와 디코더의 중간 레이어의 출력값들은 신경쓰지 않습니다.
"뭐로 가든 서울로 가면 된다"고 중간 레이어에서 어떤 값이 나왔던간에, 디코더의 최종 출력값이 입력값과 비슷하기만 하면 됩니다.
즉, 중간 결과값에 대한 어떠한 제약도 objective function(목적함수)에 없기 때문에, 중간 결과값끼리의 비교는 무의미합니다.

## Methodology

하지만 RaPP는 단순한 방법을 통해, 앞서 언급한 인코더의 중간 레이어 결과값과 디코더의 중간 레이어 결과값을 비교하는 작업을 수행합니다.

인코더와 디코더가 각각 $\ell$ 개의 레이어를 갖는 오토인코더 $A$ 에 입력값 $x$ 를 넣어 얻은 출력값 $\hat{x}=A(x)$ 을 다시 인코더 $g$ 에 통과시킵니다.
이때 얻어지는 인코더의 중간 레이어 결과값을 앞서 $x$ 를 인코더에 통과시켰을 때의 중간 레이어 결과값과 비교합니다.

$$
\text{RaPP}(x)=\sum_{i=0}^{\ell}{||g_{:i}(x)-g_{:i}\circ{A}(x)||}
$$

위의 수식을 해석해 보면, 입력 샘플 $x$ 가 주어졌을 때, 인코더 $g$ 의 $i$ 번째 레이어까지의 결과값 $g_{:i}(x)$ 에, 오토인코더를 한번 통과시킨 값 $A(x)$ 을 다시 인코더 $i$ 번째 레이어까지 통과시켜 얻은 값 $g_{:i}\circ{A}(x)$ 을 비교하는 것을 볼 수 있습니다.
그리고 이 작업을 인코더의 전체 레이어에 대해서 각각 수행하여 모두 더하는 것을 볼 수 있습니다. — 이에 우리는 하나의 scalar 값을 얻게 되어 anomaly score로 사용 가능합니다.

위의 방법이 RaPP SAP(Simple Aggregation along Pathway)입니다.
하지만 이 경우에는 각 레이어들의 차이값들을 단순히 더하는데서 아쉬움이 남아있을 수 있습니다.
즉, SAP의 경우에는 아래의 그림에서 왼쪽과 같이 분포가 있을 때, 단순히 원점으로부터의 거리를 구하는 것이라고 볼 수 있습니다.

![분포와 샘플이 주어졌을 때, Mahalanobis Distance의 개념](/assets/images/20200218/4.png)

하지만 우리는 오른쪽과 같이 분포를 고려한 거리를 계산할 수 있습니다.
이는 Mahalanobis Distance와 같은 개념이라고 볼 수 있습니다.
이를 위해서 우리는 학습 샘플들의 각 레이어별 차이값에 SVD를 활용하여 normalized distance를 구할 수 있을 것입니다.
이 방법을 RaPP NAP(Normalized Aggregation along Pathway)라고 합니다.

결과적으로 SAP와 NAP를 통해서 우리는 여러 레이어로부터의 차이값들을 하나의 scalar값으로 만들어낼 수 있고, 이를 anomaly score로 활용하여 더 나은 이상탐지를 수행할 수 있습니다.

### Intuitive Explanation

그럼 논문에서 다루지 못했던 이 알고리즘의 배경에 대해서 다소 추상적일 수 있으나 좀 더 이야기 해보겠습니다. — ICLR은 페이퍼를 8장으로 제한하고, 더 많은 장수를 사용할경우 추가 비용을 지불해야합니다.

오토인코더의 각 레이어들은 샘플로부터 (샘플을 복원하기 위한) 특징(feature)들을 추출해냅니다.
이 과정에서 복원하는데 필요하지 않은 정보들은 버려집니다.
학습된 특징들은 학습 데이터 내에서 샘플들을 구분하기 위해 필요한 정보들로 구성되어 있습니다.
만약 학습 데이터가 MNIST의 전체 숫자들을 담고 있었다면, 10가지의 숫자들을 구분하기 위한 특징들부터 우선적으로 학습될 것입니다.
만약 학습 데이터가 1가지의 숫자들로만 구성되어 있었다면, 해당 클래스 내에서 샘플들을 구분하기 위한 정보(e.g. 굵기, 기울기 등)들이 학습될 것 같습니다.

만약 비정상 샘플을 오토인코더에 통과시킨다면 어떻게 될까요?
비정상 샘플은 학습 과정에서 보지 못했던 특징(feature)들을 갖고 있을 것입니다.
이 특징들은 다른 기존의 샘플들과 구별할 수 있는 좋은 정보가 될 수 있으나, 학습 과정에서 미처 보지 못한 특징이기 때문에 아쉽게도 인코딩 과정에서 버려지게 됩니다.
결과적으로 비정상 샘플을 오토인코더에 통과시켜 복원된 값은 정상 데이터들로 학습된 특징들로만 구성되어 있을겁니다.
그럼 정상 데이터들의 특징들로만 구성된 데이터를 우리는 정상 데이터라고 부를 수 있지 않을까요?
즉, 어떤 데이터이든간에 오토인코더를 통과한 출력값은 정상 데이터의 범주에 속한다고 말할 수 있습니다.

<!-- ![학습된 특징 정보들의 집합과 이로부터 복원된 출력값]() -->

다른 관점에서 이야기 해보겠습니다.
먼저 우리는 앞선 포스팅에서 오토인코더에 샘플을 통과시키는 작업은 학습 데이터를 통해 구성된 더 낮은 차원의 다양체에 샘플을 projection 하는 것이라고 이야기하였습니다. [2]
이 다양체는 매니폴드라고 불리우며, 정상 데이터들로만 구성되어 있습니다.
즉, 일반적으로 샘플은 noise를 가지고 있고, 오토인코더를 통과시키는 과정은 이 noise를 제거하는 과정(매니폴드에 projection하는 과정)이라고 볼 수 있습니다.
따라서 이 noise의 크기가 큰 경우에는 비정상 데이터라고 간주하는 것입니다.
결론적으로 우리는 "오토인코더의 결과값은 매니폴드 위에 존재하며 정상에 속한다"라고 이야기 할 수 있습니다.

정상 샘플을 오토인코더에 통과시킨 출력값을 다시 인코더에 넣어 압축하면 어떻게 될까요?
이상적으로 보았을 때, 오토인코더의 출력값은 인코더로부터 추출된 특징들로만 이루어져 있기 때문에 인코딩 과정에서 버려지는 정보는 없을 것입니다.
즉 다르게 표현하면, 인코더의 중간 레이어들이 표현하는 공간에 존재하는 각 매니폴드 위에 항상 존재할 것입니다.
(또 다른 표현으로는, $\hat{x}$ 를 인코더의 각 레이어에 통과시키는 것은, 각 레이어 출력값들이 존재하는 공간에 $\hat{x}$ 를 translation 한 것이라고 볼 수 있습니다.)
이에 반해 처음 인코더를 통과하는 값은 아직 매니폴드 위에 존재하지 않습니다.
따라서 우리는 이 두 값의 차이를 계산할 수 있는 것입니다.

![인코더를 통과하면서 RaPP의 계산이 이루어지는 과정](/assets/images/20200218/5.png)

다시한번 이야기하면, 오토인코더를 통과하여 복원된 값은 정상 데이터에 속하며, 그 정상 데이터를 이루는 특징들은 학습 데이터로부터 학습된 것입니다.
그럼 만약 비정상 데이터를 오토인코더에 통과시키면 어떻게 될까요?
그럼 오토인코더를 통과한 비정상 데이터는 정상 데이터들로 구성된 매니폴드에 projection 될 것이고, 정상 데이터들의 특징들로만 구성된 나름의 정상 데이터가 됩니다.
이 값을 이제 다시 인코더에 넣으면 어떻게 될까요?
여전히 중간 레이어 결과값은 각 공간의 매니폴드 위에 존재할 것입니다.
그럼 마찬가지로 인코더를 처음 통과할 때의 중간 결과값과 비교하면 됩니다.

### Equations

이미 학습된 오토인코더 $A=f\circ{g}$ 가 있을 때, 매니폴드 $M_0$ 은 다음과 같이 정의 할 수 있습니다. [3]

$$
\forall{x}\in{M_0}\text{, }x=A(x)\text{ where }M_0=\{A(x):x\in\mathbb{R}^n\}.
$$

이것은 입력 데이터가 존재하는 공간(space)에 정의된 매니폴드라고 볼 수 있고, 마찬가지로 $i$ 번째 레이어의 결과값들이 존재하는 공간에도 매니폴드가 정의될 수 있을 것입니다.

$$
M_i=\{g_{:i}(x):x\in{M_0}\}
$$

이러한 관점에서 $g$ 와 $f$ 는 $M_0$ 과 $M_\ell$ 사이의 맵핑 함수이며 서로 역함수 관계라고 볼 수 있습니다.

이때 가상의 디코더 함수 $\tilde{f}$ 가 존재한다고 해보겠습니다.

$$\begin{gathered}
\tilde{f}=\tilde{f}_1\circ\cdots\circ\tilde{f}_\ell \\
\forall{x}\in{M_\ell}\text{, }\tilde{f}(x)=f(x).
\end{gathered}$$

그리고 이 디코더 $\tilde{f}$ 는 인코더 $g$ 와 대칭대는 구조를 지녔으며, 이 가상 디코더의 각 레이어는 인코더의 대응되는 레이어의 역함수라고 가정해보겠습니다.

$$
\forall{a}\in{M_i}\text{, }a=(g_i\circ\tilde{f}_i)(a).
$$

이런 디코더가 있다면 우리는 디코더 중간 레이어의 중간 레이어 결과값을 인코더의 중간 레이어 결과값에 바로 비교 가능할 것입니다.
즉, 이 디코더의 중간 레이어 결과값을 아래와 같이 $\tilde{h}_{i}(x)$ 라고 정의할 때, 우리는 이 $\tilde{h}_{i}(x)$ 와 $g_{:i}(x)$ 를 비교하면 됩니다.

$$\begin{gathered}
\text{RaPP}(x)=\sum_{i=0}^{\ell}{||g_{:i}(x)-\tilde{h}_i(x)||}\text{,} \\
\text{where }\tilde{h}_i(x)=\tilde{f}_{\ell:i+1}\circ{g}(x).
\end{gathered}$$

그런데 알고보면 $\tilde{h}_{i}(x)$ 는 아래와 같이 전개할 수 있습니다.

$$\begin{aligned}
\forall{x}\in\mathbb{R}^n\text{, }\tilde{h}_i(x)&=\tilde{f}_{\ell:i+1}\circ{g}(x) \\
&=\tilde{f}_{\ell:i+1}\circ{g_{i+1:}}\circ{g}(x) \\
&=(g_{:i}\circ{\tilde{f}_{i:1}})\circ{\tilde{f}_{\ell:i+1}}\circ{g}(x)\text{, because }g(x)\in{M_\ell}\\
&=g_{:i}\circ{\tilde{f}}\circ{g}(x) \\
&=g_{:i}\circ{f}\circ{g}(x) \\
&=g_{:i}\circ{A}(x) \\
&=g_{:i}(\hat{x})\text{, where }\hat{x}=A(x)\in{M_0}.
\end{aligned}$$

위와 같이 $\tilde{h}_{i}(x)$ 는 $g_{:i}(\hat{x})$ 와 같음(equivalent)을 알 수 있습니다. 따라서 RaPP는 아래와 같이 정의 됩니다.

$$\begin{aligned}
\text{RaPP}(x)&=\sum_{i=0}^{\ell}{||g_{:i}(x)-\tilde{h}_i(x)||} \\
&=\sum_{i=0}^{\ell}{||g_{:i}(x)-g_{:i}(\hat{x})||}
\end{aligned}$$

![수식에 따라서 우리는 RaPP를 통해 가상의 디코더에 대한 중간 레이어 결과값을 얻을 수 있습니다.](/assets/images/20200218/6.png)

## Experiments

우리는 다양한 실험을 통해 RaPP를 검증하고자 하였습니다.
먼저 MNIST와 FMNIST 같은 널리 알려진 데이터셋을 통해서 기존에 출판된 논문들의 성능과 비교하는 작업을 거치고, 마키나락스가 주로 타겟하고 있는 tabular 데이터셋에 대해서도 실험을 수행하였습니다.
벤치마크 데이터셋에 대해서 실험을 수행한 결과는 아래와 같습니다.

![MNIST와 FMNIST에 대한 실험 결과](/assets/images/20200218/7.png)

결과에서 볼 수 있듯이, 다양한 오토인코더(AE, VAE[4], AAE[5])에 NAP를 적용하였을 때, 기존에 출판된 논문(OCNN[6], GPND[3], DSVDD[7], GT[8])들보다 더 뛰어난 성능을 보이는 것을 확인할 수 있었습니다.
특히 VAE에 NAP를 적용하였을 떄가 가장 뛰어난 성능을 보였습니다.
또한, OCNN, GPND, DSVDD와 같이 One Class Classification 문제로 정의한 알고리즘들은 아쉽게도 multimodal normality 케이스에서 제대로 동작하지 못하는 것을 확인할 수 있습니다.

또한 아래와 같이 multimodal normality 케이스에 대해서 각 클래스 별로 살펴보았을 때, 기존 대비 RaPP가 ('1'에서의 큰 성능 향상을 포함하여) 대부분의 클래스에서 성능을 높이는 것을 확인할 수 있습니다.
자세한 실험 셋팅은 논문을 참고바랍니다.

![MNIST 클래스별 AUROC](/assets/images/20200218/10.png)

MNIST와 같은 이미지 데이터들은 tabular 데이터셋과 양상이 다를 수 있기 때문에, tabular 데이터셋에 대해서도 RaPP를 실험하였습니다.
이때는 기존에 출판된 논문들이 tabular 데이터셋에 대해서 성능을 제공하지 않았을 뿐더러, 대부분 convolutional layer를 사용한 상태이므로 적용하기가 힘들었습니다.
따라서 기존의 오토인코더와 RaPP를 적용한 결과를 비교하여, RaPP의 적용에 따른 성능 향상을 실험하고자 하였습니다.
우선 실험에 사용된 tabular 데이터셋은 아래와 같이 구성되어 있습니다.

![Tabular 데이터셋에 대한 설명](/assets/images/20200218/8.png)

나중에 보니 STL(steel) 데이터셋은 워낙 클래스당 샘플 수가 적어서 train/valid/test random split에 따라 굉장히 편차가 심한 결과를 보여주었습니다.

![Tabular 데이터셋에 대한 실험 결과](/assets/images/20200218/9.png)

실험 결과에 따르면, RaPP는 multimodal normality 케이스에서 더 뛰어난 모습을 보여줍니다.
Multimodal normality 케이스에서는 STL을 제외하고 모든 데이터셋에서 RaPP를 통해 성능을 향상할 수 있었습니다.
반면에 Unimodal normality 케이스에서는 총 10가지 경우 중에서 6가지 경우에 RaPP가 뛰어난 모습을 보여줍니다.
다만, 대부분의 tabular 데이터셋은 시계열 데이터셋인데 반해, 이 실험에서는 RaPP를 적용할 때 iid로 가정하고 적용하였습니다. -- 시계열 데이터셋의 경우에는 RNN과 같은 모델을 활용하지 않더라도 윈도잉과 같은 기법을 통해 시계열의 성질을 어느정도 반영할 수 있습니다.

## Discussion & Conclusion

재미있게도 MNIST와 FMNIST의 실험결과를 보면 기존의 anomaly detection 논문들의 성능이 reconstruction error 기반의 baseline anomaly detection 성능보다도 낮은 것을 볼 수 있습니다.
이것은 AE를 비롯한 VAE, AAE에 대한 정확한 구현과 실험 및 검증이 원활하게 이루어지지 않은것이 아닌가 생각해볼 수 있습니다.
실제로 앞서 포스팅에서 언급한대로 주류 연구 분야가 아니다보니 생기는 문제로 생각해볼 수 있으며, 제대로 된 벤치마크 성능의 부재는 연구를 진행하며 느꼈던 큰 아쉬움 점이기도 합니다.

따라서 RaPP를 실험할 때에는 Unimodal/Multimodal Normality 케이스로 나누어 실험을 진행하였으며, MNIST와 FMNIST 이외에도 다양한 tabular 데이터셋에 대해서도 anomaly detection 실험을 수행하였습니다.
하지만 워낙 다양한 실험을 진행하다보니 아쉽게도 다양한 케이스에 대해서 최적의 성능을 뽑아내진 못하였으며, 페이퍼에 기재된 성능은 아직 upper bound에 대해서 margin이 남아 있습니다.

MNIST와 FMNIST 같은 이미지 데이터셋을 비롯하여, 페이퍼 상의 모든 실험들은 fully-connected layer를 활용한 오토인코더들로 구현되었습니다.
아쉽게도 RaPP 알고리즘을 바로 Convolutional Layer에 적용하는 것은 아직 연구가 필요한 부분입니다.

이번 포스팅에서는 마키나락스에서 ICLR에 출판한 논문인 RaPP에 대해서 살펴보았습니다.
논문이라는 제약 때문에 미처 페이퍼에서는 다루지 못했던 내용들과 함께, 전반적인 내용들을 보다 쉽게 풀어서 설명하고자 하였습니다.

요약하자면 RaPP는 기존의 훈련방식을 통해 학습된 오토인코더에서 더 나은 anomaly score를 구하는 방법을 제안한 것이라고 볼 수 있습니다.
특히 NAP 방식을 통해서 우리는 여러가지 데이터셋에서 더 높은 성능의 anomaly detection을 수행할 수 있었습니다.
결과적으로 RaPP는 목적함수의 수정이 없이 성능을 개선했다는 장점이 있으나, NAP의 계산과정이 무겁다는 단점이 존재합니다. -- 이에 대해서는 Appendix A에서 다루고 있습니다.

## References

- [1] Ki Hyun Kim et al., Rapp: Novelty Detection with Reconstruction along Projection Pathway, ICLR, 2020
- [2] Lei et al., Geometric Understanding of Deep Learning, Arxiv, 2018
- [3] Stanislav Pidhorskyi et al., Generative Probabilistic Novelty Detection with Adversarial Autoencoders, NeurIPS, 2018
- [4] Kingma et al., Auto-Encoding Variational Bayes, ICLR, 2014
- [5] Makhzani et al., Adversarial autoencoders. Arxiv, 2015.
- [6] Raghavendra Chalapathy et al., Anomaly detection using one-class neural networks. arXiv preprint arXiv:1802.06360, 2018.
- [7] Lukas Ruff et al., Deep one-class classification. In ICML, 2018.
- [8] Izhak Golan and Ran El-Yaniv. Deep anomaly detection using geometric transformations. NIPS, 2018.
- [9] Ki Hyun Kim, Operational AI: Building a Lifelong Learning Anomaly Detection System, DEVIEW, 2019
