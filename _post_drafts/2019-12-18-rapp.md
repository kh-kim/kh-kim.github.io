---
title: RaPP: Novelty Detection with Reconstruction along Projection Pathway
key: 20191218
tags: AnomalyDetection
category: blog
---

## Overview

이번 포스팅은 마키나락스에서 2020년 4월에 에티오피아에서 열리는 ICLR에 출판한 페이퍼인 RaPP 방법에 대해서 다루도록 하겠습니다.
이 방법은 기존의 오토인코더(autoencoders, AE)에서의 reconstruction error 기반의 이상탐지(anomaly detection)를 확장한 것으로, 학습을 위한 training objective는 수정하지 않고 테스트 과정에서의 anomaly score metric만을 수정하여 이상탐지 성능을 끌어올린 것에 의의가 있습니다.
이 포스팅을 통해서 RaPP의 motivation과 직관적인 해석, 그리고 수식적인 해석과 실험 결과를 전달드리고자 합니다.
추가로 ICLR 학회의 페이지수 제한과 그 밖의 다양한 이유로 페이퍼에 미처 적지 못했던 RaPP의 인사이트를 공유하고자 합니다.

### Overall Process

좀 더 나아가기에 앞서, RaPP의 동작 방식에 대해서 설명하고자 합니다.
앞서 언급하였듯이, RaPP는 기존의 다양한 오토인코더 위에서 동작하는 anomaly score metric 입니다.
따라서 오토인코더의 training objective의 수정 없이, 단순히 이미 학습된 오토인코더를 활용하여 더 나은 이상탐지 성능을 제공합니다.

RaPP의 동작 원리는 다음과 같습니다.

![RaPP 수행 방법]()

먼저, 입력 샘플 $x$ 를 오토인코더 $A$ 의 인코더 $g$ 와 디코더 $f$ 에 차례로 통과시킵니다.
그럼 우리는 결과물 $\hat{x}$ 을 얻을 수 있습니다.
이때 기존의 reconstruction error 기반의 anomaly score는 다음과 같이 정의 될 수 있습니다.

$$
\begin{aligned}
\text{score}(x)&=||f\circ{g}(x)-x||_2 \\
&=||\hat{x}-x||_2
\end{aligned}
$$

이때 인코더 내부의 $i$ 번째 레이어 $g_i$ 의결과값을 $h_i$ 라고 하겠습니다.

$$
h_i=g_{1:i}(x)
$$

RaPP는 여기서 $\hat{x}$ 을 다시 인코더에 통과시킵니다.
이때 마찬가지로 인코더 내부의 각 레이어의 결과값을 구할 수 있을 것입니다.
$i$ 번째 레이어의 그것을 $\hat{h}_i$ 라고 하겠습니다.

$$
\begin{aligned}
\hat{h}_i&=g_{1:i}(\hat{x}) \\
&=g_{1:i}\circ{f}\circ{g}(x)
\end{aligned}
$$

그럼 RaPP는 다음과 같이 $h_i$ 과 $\hat{h}_i$ 들의 concatenation 한 결과 벡터 사이의 distance로 정의됩니다.

$$
\text{RaPP}(x)=\Big|\Big|[h_1;\cdots;h_\ell]-[\hat{h}_1;\cdots;\hat{h}_\ell]\Big|\Big|
$$

여기서 경우에 따라 L2 Norm 또는 mahalanobis distance를 distance metric으로 사용합니다.

## Motivation

RaPP는 굉장히 단순한 방법으로 anomaly score metric의 성능을 향상 시킵니다.
기존 복원 오차(reconstruction error) 기반의 이상탐지 기법은 보통 잘 동작하지만, 가끔 아래와 같은 상황을 맞이할 수 있습니다.

아래의 예제는 MNIST에서 실제 오토인코더를 활용하여 reconstruction error 기반의 이상탐지를 수행할 경우 겪게 되는 현상입니다. ‘1’을 novelty class로 설정하고, 나머지 9개의 숫자들을 학습데이터로 삼아 학습하였을 때, 테스트 과정에서 오토인코더는 학습 과정에서 보지 못했던 ‘1’ 클래스의 샘플들을 성공적으로 복원해냅니다. 심지어 아래의 그림에 따르면 학습에서 보았던 클래스에 속하는 일부 샘플들보다도 복원 오차가 더 낮은 것을 볼 수 있습니다.

![]()

이러한 경우에는 reconstruction error를 기준으로 anomalous sample을 탐지하는 전략이 실패합니다. AUROC의 경우에도 심지어 0.5보다 낮은것을 확인할 수 있습니다. — 이는 오히려 reconstruction error가 낮은 것을 선택하는 것이 더 나은 전략임을 말합니다. 아마도 우리는 ‘1’은 모양이 너무 단순하여, 다른 9개의 클래스로부터 학습된 특징(feature)들로 표현이 가능하기 때문에 복원이 잘 된 것이 아닐까 추측해볼 수 있습니다.

이처럼 단순이 오토인코더의 입력과 출력을 비교하는 전략은 훌륭하긴 하지만 아쉬움이 여전이 남아있습니다. RaPP는 이때의 아쉬움을 달래고자, 양 끝의 데이터만 비교하는 방법을 좀 더 개선하고자 합니다.

만약 오토인코더의 입력과 출력만 비교하는 대신에, 인코더의 각 hidden layer의 출력값들과 디코더의 hidden layer의 출력값들을 비교하는 것은 어떨까요? 지난 포스팅에서 우리는 오토인코더의 인코더는 압축을 담당하고, 디코더는 압축의 복원(해제)을 담당한다고 이야기하였습니다. 그럼 압축 중간 과정 결과물과 복원 중간 과정의 결과물을 비교한다면, 기존의 입력/출력 값만을 비교하는 것에 비해서, 훨씬 더 자세한 비교를 수행할 수 있지 않을까요?

![]()

하지만 아쉽게도 이 방법은 기존의 방법에서는 쉽지 않습니다. 우선 오토인코더는 입력과 출력의 차이만을 최소화하도록 학습되었기 때문입니다. — 그리고 그전에 오토인코더가 당연히 대칭의 구조를 가지고 있어야겠지요.

$$
\mathcal{L}(\theta)=\sum_{i=1}^{N}{||x_i-A_\theta(x_i)||}
$$

따라서 딥러닝의 학습 과정에서 신경망은 입력 $x_i$ 와 출력 $A(x_i)$ 에 대해서만 신경쓸 뿐, 인코더와 디코더의 중간 레이어의 출력값들은 신경쓰지 않습니다. “뭐로 가든 서울로 가면 된다”고 중간 레이어에서 어떤 값이 나왔던간에, 디코더의 최종 출력값이 입력값과 비슷하기만 하면 됩니다. 즉, 중간 결과값에 대한 어떠한 제약도 objective function(목적함수)에 없기 때문에, 중간 결과값끼리의 비교는 무의미합니다.

## Methodology

하지만 RaPP는 단순한 방법을 통해, 앞서 언급한 인코더의 중간 레이어 결과값과 디코더의 중간 레이어 결과값을 비교하는 작업을 수행합니다.

인코더와 디코더가 각각 $L$ 개의 레이어를 갖는, 오토인코더 $A$ 에 입력값 $x$ 를 넣어 얻은 출력값 $\hat{x}=A(x)$ 을 다시 인코더 $g$ 에 통과시킵니다. 이때 얻어지는 인코더의 중간 레이어 결과값을 앞서 $x$ 를 인코더에 통과시켰을 때의 중간 레이어 결과값과 비교합니다.

$$
\text{RaPP}(x)=\sum_{i=0}^{L}{||g_{:i}(x)-g_{:i}\circ{A}(x)||}
$$

위의 수식을 해석해 보면, 입력 샘플 $x$ 가 주어졌을 때, 인코더 $g$ 의 $i$ 번째 레이어까지의 결과값 $g_{:i}(x)$ 에, 오토인코더를 한번 통과시킨 값 $A(x)$ 을 다시 인코더 $i$ 번째 레이어까지 통과시켜 얻은 값 $g_{:i}\circ{A}(x)$ 을 비교하는 것을 볼 수 있습니다. 그리고 이 작업을 인코더의 전체 레이어에 대해서 각각 수행하여 모두 더하는 것을 볼 수 있습니다. — 이에 우리는 하나의 scalar 값을 얻게 되어 anomaly score로 사용 가능합니다.

위의 방법이 RaPP SAP(Simple Aggregation along Pathway)입니다. 하지만 이 경우에는 각 레이어들의 차이값들을 단순히 더하는데서 아쉬움이 남아있을 수 있습니다. 즉, SAP의 경우에는 아래의 그림에서 왼쪽과 같이 분포가 있을 때, 단순히 원점으로부터의 거리를 구하는 것이라고 볼 수 있습니다.

![]()

하지만 우리는 오른쪽과 같이 분포를 고려한 거리를 계산할 수 있습니다. 이는 Mahalanobis Distance와 같은 개념이라고 볼 수 있습니다. 이를 위해서 우리는 학습 샘플들의 각 레이어별 차이값에 SVD를 활용하여 normalized distance를 구할 수 있을 것입니다. 이 방법을 RaPP NAP(Normalized Aggregation along Pathway)라고 합니다.

결과적으로 SAP와 NAP를 통해서 우리는 여러 레이어로부터의 차이값들을 하나의 scalar값으로 만들어낼 수 있고, 이를 anomaly score로 활용하여 더 나은 이상탐지를 수행할 수 있습니다.

### Intuitive Explanation

그럼 논문에서 다루지 못했던 이 알고리즘의 배경에 대해서 다소 추상적일 수 있으나 좀 더 이야기 해보겠습니다. — ICLR은 페이퍼를 8장으로 제한하고, 더 많은 장수를 사용할경우 추가 비용을 지불해야합니다.

오토인코더의 각 레이어들은 샘플로부터 (샘플을 복원하기 위한) 특징(feature)들을 추출해냅니다. 이 과정에서 복원하는데 필요하지 않은 정보들은 버려집니다. 학습된 특징들은 학습 데이터 내에서 샘플들을 구분하기 위해 필요한 정보들로 구성되어 있습니다. 만약 학습 데이터가 MNIST의 전체 숫자들을 담고 있었다면, 10가지의 숫자들을 구분하기 위한 특징들부터 우선적으로 학습될 것입니다. 만약 학습 데이터가 1가지의 숫자들로만 구성되어 있었다면, 해당 클래스 내에서 샘플들을 구분하기 위한 정보(e.g. 굵기, 기울기 등)들이 학습될 것 같습니다.

만약 비정상 샘플을 오토인코더에 통과시킨다면 어떻게 될까요? 비정상 샘플은 학습 과정에서 보지 못했던 특징(feature)들을 갖고 있을 것입니다. 이 특징들은 다른 기존의 샘플들과 구별할 수 있는 좋은 정보가 될 수 있으나, 학습 과정에서 미처 보지 못한 특징이기 때문에 아쉽게도 인코딩 과정에서 버려지게 됩니다. 결과적으로 비정상 샘플을 오토인코더에 통과시켜 복원된 값은 정상 데이터들로 학습된 특징들로만 구성되어 있을겁니다. 그럼 정상 데이터들의 특징들로만 구성된 데이터를 우리는 정상 데이터라고 부를 수 있지 않을까요? 즉, 어떤 데이터이든간에 오토인코더를 통과한 출력값은 정상 데이터의 범주에 속한다고 말할 수 있습니다.

다른 관점에서 이야기 해보겠습니다. 먼저 우리는 앞선 포스팅에서 오토인코더에 샘플을 통과시키는 작업은 학습 데이터를 통해 구성된 더 낮은 차원의 다양체에 샘플을 projection 하는 것이라고 이야기하였습니다. 이 다양체는 매니폴드라고 불리우며, 정상 데이터들로만 구성되어 있습니다. 즉, 일반적으로 샘플은 noise를 가지고 있고, 오토인코더를 통과시키는 과정은 이 noise를 제거하는 과정(매니폴드에 projection하는 과정)이라고 볼 수 있습니다. 따라서 이 noise의 크기가 큰 경우에는 비정상 데이터라고 간주하는 것입니다. 결론적으로 우리는 “오토인코더의 결과값은 매니폴드 위에 존재하며 정상에 속한다”라고 이야기 할 수 있습니다.

정상 샘플을 오토인코더에 통과시킨 출력값을 다시 인코더에 넣어 압축하면 어떻게 될까요? 이상적으로 보았을 때, 오토인코더의 출력값은 인코더로부터 추출된 특징들로만 이루어져 있기 때문에, 인코딩 과정에서 버려지는 정보는 없을 것입니다. 즉, 다르게 표현하면, 인코더의 중간 레이어들이 표현하는 공간에 존재하는 각 매니폴드 위에 항상 존재할 것입니다. (또 다른 표현으로는, $\hat{x}$ 를 인코더의 각 레이어에 통과시키는 것은, 각 레이어 출력값들이 존재하는 공간에 $\hat{x}$ 를 translation 한 것이라고 볼 수 있습니다.) 이에 반해 처음 인코더를 통과하는 값은 아직 매니폴드 위에 존재하지 않습니다. 따라서 우리는 이 두 값의 차이를 계산할 수 있는 것입니다.

![]()

다시한번 이야기하면, 오토인코더를 통과하여 복원된 값은 정상 데이터에 속하며, 그 정상 데이터를 이루는 특징들은 학습 데이터로부터 학습된 것입니다. 그럼 만약 비정상 데이터를 오토인코더에 통과시키면 어떻게 될까요? 그럼 오토인코더를 통과한 비정상 데이터는 정상 데이터들로 구성된 매니폴드에 projection 될 것이고, 정상 데이터들의 특징들로만 구성된 나름의 정상 데이터가 됩니다. 이 값을 이제 다시 인코더에 넣으면 어떻게 될까요? 여전히 중간 레이어 결과값은 각 공간의 매니폴드 위에 존재할 것입니다. 그럼 마찬가지로 인코더를 처음 통과할 때의 중간 결과값과 비교하면 됩니다.

### Equations

## Experiments

## Discussion

## Conclusion
